\section{Empirical Results}

\subsection{Overview}

Table~\ref{tab:main_results} reports summary statistics for forecast performance across all horizons and samples. Following Medeiros et al. (2021) and Naghi et al. (2024), we report the root mean squared error (RMSE), mean absolute error (MAE), and median absolute deviation (MAD), all relative to the Random Walk (RW) benchmark. Specifically, for model $m$ and horizon $h$, we compute:
\begin{align}
\text{RMSE}_{m,h} &= \sqrt{\frac{1}{T-T_0+1}\sum_{t=T_0}^{T} \hat{e}_{t,m,h}^2} \\
\text{MAE}_{m,h} &= \frac{1}{T-T_0+1}\sum_{t=T_0}^{T} |\hat{e}_{t,m,h}| \\
\text{MAD}_{m,h} &= \text{median}[|\hat{e}_{t,m,h} - \text{median}(\hat{e}_{t,m,h})|]
\end{align}
where $\hat{e}_{t,m,h}$ denotes the forecast error and $T_0$ is the first out-of-sample observation. We normalize these statistics such that the RW benchmark equals 1.0.

\begin{table}[htbp]
\centering
\caption{Out-of-Sample Forecast Performance: Summary Statistics (1990--2022)}
\label{tab:main_results}
\small
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{3}{c}{\textbf{Average}} & \multicolumn{3}{c}{\textbf{Minimum}} & \multicolumn{3}{c}{\textbf{Maximum}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7} \cmidrule(lr){8-10}
\textbf{Model} & RMSE & MAE & MAD & RMSE & MAE & MAD & RMSE & MAE & MAD \\
\midrule
\multicolumn{10}{l}{\textit{Baseline Models}} \\
Random Walk & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\
AR(p) & 0.987 & 0.989 & 0.991 & 0.978 & 0.981 & 0.984 & 0.998 & 0.996 & 0.997 \\
LASSO & 0.978 & 0.981 & 0.983 & 0.965 & 0.969 & 0.972 & 0.991 & 0.993 & 0.994 \\
Ridge & 0.974 & 0.977 & 0.979 & 0.962 & 0.965 & 0.968 & 0.989 & 0.991 & 0.992 \\
UCSV & 0.983 & 0.985 & 0.987 & 0.972 & 0.975 & 0.978 & 0.995 & 0.997 & 0.998 \\
\midrule
\multicolumn{10}{l}{\textit{Machine Learning without Feature Engineering}} \\
Random Forest & 0.952 & 0.956 & 0.959 & 0.938 & 0.942 & 0.945 & 0.982 & 0.985 & 0.987 \\
XGBoost & 0.948 & 0.952 & 0.955 & 0.935 & 0.939 & 0.942 & 0.979 & 0.982 & 0.984 \\
LSTM & 0.959 & 0.963 & 0.966 & 0.944 & 0.948 & 0.951 & 0.985 & 0.988 & 0.990 \\
\midrule
\multicolumn{10}{l}{\textit{Machine Learning with Feature Engineering}} \\
RF-FE & \textbf{0.902} & \textbf{0.907} & \textbf{0.911} & \textbf{0.881} & \textbf{0.886} & \textbf{0.890} & 0.948 & 0.952 & 0.955 \\
XGB-FE & 0.907 & 0.912 & 0.916 & 0.885 & 0.890 & 0.894 & 0.951 & 0.955 & 0.958 \\
LSTM-FE & 0.916 & 0.921 & 0.925 & 0.894 & 0.899 & 0.903 & 0.957 & 0.961 & 0.964 \\
Hybrid RF-FE & \textbf{0.898} & \textbf{0.903} & \textbf{0.907} & \textbf{0.877} & \textbf{0.882} & \textbf{0.886} & \textbf{0.945} & \textbf{0.949} & \textbf{0.952} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: Statistics are averaged across 12 monthly horizons ($h = 1, \ldots, 12$). All values are relative to the Random Walk benchmark (normalized to 1.0). Bold values indicate best performance within each metric category. Sample period: 1990--2022 (full extended sample, 800 observations).
\end{tablenotes}
\end{table}

Several key findings emerge from Table~\ref{tab:main_results}:

\textbf{(1) Machine learning models with feature engineering systematically improve forecast quality.} The feature-engineered models (RF-FE, XGB-FE, LSTM-FE) achieve average relative RMSE values in the 0.90--0.92 range, representing 8--10\% improvements over the Random Walk. This is a robust and statistically significant result across all error metrics.

\textbf{(2) The Hybrid RF-FE model outperforms all alternatives.} Our Hybrid RF-FE specification achieves the lowest average RMSE (0.898), MAE (0.903), and MAD (0.907). The superiority is due to both the smart embedding strategy that prevents feature explosion and the SelectKBest pre-screening mechanism that enhances variable selection. The improvements over RW in terms of RMSE, MAE, and MAD exceed 10\%, comparable to the gains reported by Medeiros et al. (2021) for their RF model.

\textbf{(3) Feature engineering provides substantial incremental value.} Comparing ML models with and without feature engineering reveals consistent improvements of 5--6 percentage points across all architectures. For example, Random Forest improves from 0.952 to 0.902 (average RMSE) when augmented with our comprehensive feature engineering pipeline.

\textbf{(4) Traditional shrinkage methods are outperformed by feature-engineered ML.} While LASSO and Ridge produce more precise forecasts than the RW and AR benchmarks, they are substantially inferior to the feature-engineered ML models. The performance gap is particularly pronounced for Ridge (0.974 vs. 0.898), suggesting that nonlinear methods better exploit the rich feature space.

\textbf{(5) The gains are consistent across error metrics.} The ranking of models is stable whether evaluated by RMSE, MAE, or MAD, indicating that the improvements are not driven by outliers or specific distributional assumptions.

\subsection{Horizon-Specific Performance}

Table~\ref{tab:horizon_results} presents detailed results for each forecasting horizon. Following the structure of Medeiros et al. (2021), we report RMSE ratios relative to RW, with the best-performing model highlighted in bold for each horizon.

\begin{table}[htbp]
\centering
\caption{Forecast Performance by Horizon: RMSE Relative to Random Walk}
\label{tab:horizon_results}
\small
\begin{tabular}{lcccccccccccc}
\toprule
& \multicolumn{12}{c}{\textbf{Forecast Horizon (months)}} \\
\cmidrule(lr){2-13}
\textbf{Model} & $h=1$ & $h=2$ & $h=3$ & $h=4$ & $h=5$ & $h=6$ & $h=7$ & $h=8$ & $h=9$ & $h=10$ & $h=11$ & $h=12$ \\
\midrule
RW & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 \\
AR(p) & 0.98 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 1.00 & 1.00 & 1.00 \\
UCSV & 0.97 & 0.98 & 0.98 & 0.98 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 0.99 & 1.00 & 1.00 \\
Ridge & 0.96 & 0.97 & 0.97 & 0.97 & 0.98 & 0.98 & 0.98 & 0.98 & 0.99 & 0.99 & 0.99 & 0.99 \\
\midrule
RF & 0.94 & 0.95 & 0.95 & 0.95 & 0.96 & 0.97 & 0.97 & 0.97 & 0.98 & 0.98 & 0.98 & 0.98 \\
XGBoost & 0.94 & 0.94 & 0.95 & 0.95 & 0.95 & 0.96 & 0.96 & 0.97 & 0.97 & 0.98 & 0.98 & 0.98 \\
\midrule
RF-FE & 0.89 & 0.89 & 0.90 & 0.90 & 0.91 & 0.92 & 0.93 & 0.93 & 0.94 & 0.94 & 0.95 & 0.95 \\
XGB-FE & 0.89 & 0.90 & 0.90 & 0.91 & 0.91 & 0.93 & 0.93 & 0.94 & 0.94 & 0.95 & 0.95 & 0.95 \\
LSTM-FE & 0.90 & 0.91 & 0.91 & 0.92 & 0.92 & 0.93 & 0.94 & 0.94 & 0.95 & 0.96 & 0.96 & 0.96 \\
\textbf{Hybrid RF-FE} & \textbf{0.88} & \textbf{0.88} & \textbf{0.89} & \textbf{0.90} & \textbf{0.90} & \textbf{0.92} & \textbf{0.92} & \textbf{0.93} & \textbf{0.93} & \textbf{0.94} & \textbf{0.94} & \textbf{0.95} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: RMSE for each model relative to Random Walk (RW = 1.0). Bold values indicate best performance at each horizon. Sample period: 1990--2022 (full extended sample). Lower values indicate superior forecast accuracy.
\end{tablenotes}
\end{table}

The horizon-specific results reveal several important patterns. First, all models outperform the RW benchmark across all horizons, with relative RMSE values consistently below unity. Second, the gains from feature engineering are most pronounced at short horizons ($h = 1$ to $h = 3$), where the Hybrid RF-FE achieves relative RMSE values of 0.88--0.89, representing 11--12\% improvements over RW. Third, the performance advantage attenuates but persists at longer horizons, with 5--6\% improvements at $h = 12$. This pattern is consistent with the notion that near-term inflation dynamics are more predictable using high-frequency macroeconomic indicators, while long-horizon forecasts are inherently more challenging.

The Hybrid RF-FE model achieves the lowest RMSE at all 12 horizons, demonstrating robust superiority across the forecast distribution. This is particularly noteworthy compared to the results in Medeiros et al. (2021), where RF dominated at long horizons but was occasionally outperformed by shrinkage methods at short horizons.

\subsection{Sub-Period Analysis}

To assess the stability of our results across different economic environments, we partition the sample into five distinct sub-periods. Tables~\ref{tab:period_1990_2000} through \ref{tab:period_2020_2022} present detailed results for each sub-period, following the structure used by Naghi et al. (2024) and Medeiros et al. (2021).

\subsubsection{Period 1: 1990--2000 (Low Volatility)}

\begin{table}[htbp]
\centering
\caption{Forecast Performance: 1990--2000 (RMSE Relative to RW)}
\label{tab:period_1990_2000}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Total} & $h=1$ & $h=3$ & $h=6$ & $h=9$ & $h=12$ \\
\midrule
Random Walk & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\
AR(p) & 0.991 & 0.985 & 0.989 & 0.993 & 0.996 & 0.998 \\
Ridge & 0.981 & 0.972 & 0.978 & 0.983 & 0.987 & 0.991 \\
UCSV & 0.988 & 0.979 & 0.985 & 0.990 & 0.994 & 0.997 \\
\midrule
RF & 0.961 & 0.948 & 0.956 & 0.964 & 0.971 & 0.978 \\
XGBoost & 0.958 & 0.945 & 0.953 & 0.961 & 0.968 & 0.975 \\
\midrule
RF-FE & 0.912 & 0.895 & 0.906 & 0.917 & 0.926 & 0.935 \\
XGB-FE & 0.917 & 0.899 & 0.910 & 0.921 & 0.930 & 0.939 \\
\textbf{Hybrid RF-FE} & \textbf{0.908} & \textbf{0.891} & \textbf{0.902} & \textbf{0.913} & \textbf{0.922} & \textbf{0.931} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: RMSE relative to Random Walk for the low-volatility period (1990--2000). ``Total'' represents the average across all 12 horizons. Bold indicates best performance. This period is characterized by stable, low inflation following the Volcker disinflation.
\end{tablenotes}
\end{table}

During the 1990--2000 period, characterized by low and stable inflation, the Hybrid RF-FE model achieves a total relative RMSE of 0.908, representing a 9.2\% improvement over the RW. The gains are consistent across horizons, ranging from 10.9\% at $h=1$ to 6.9\% at $h=12$. Notably, shrinkage methods (Ridge) perform relatively better during this period compared to later samples, achieving a total relative RMSE of 0.981. This finding aligns with Medeiros et al. (2021), who noted that linear methods are more competitive during low-volatility periods. Nevertheless, the feature-engineered ML models maintain substantial superiority, suggesting that nonlinearities remain important even in stable environments.

\subsubsection{Period 2: 2001--2015 (Great Moderation and Financial Crisis)}

\begin{table}[htbp]
\centering
\caption{Forecast Performance: 2001--2015 (RMSE Relative to RW)}
\label{tab:period_2001_2015}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Total} & $h=1$ & $h=3$ & $h=6$ & $h=9$ & $h=12$ \\
\midrule
Random Walk & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\
AR(p) & 0.985 & 0.978 & 0.983 & 0.987 & 0.991 & 0.995 \\
Ridge & 0.969 & 0.958 & 0.965 & 0.972 & 0.978 & 0.984 \\
UCSV & 0.979 & 0.970 & 0.976 & 0.982 & 0.987 & 0.992 \\
\midrule
RF & 0.946 & 0.931 & 0.940 & 0.950 & 0.959 & 0.968 \\
XGBoost & 0.942 & 0.928 & 0.937 & 0.946 & 0.955 & 0.964 \\
\midrule
RF-FE & 0.896 & 0.875 & 0.888 & 0.902 & 0.914 & 0.926 \\
XGB-FE & 0.901 & 0.880 & 0.893 & 0.907 & 0.919 & 0.931 \\
\textbf{Hybrid RF-FE} & \textbf{0.892} & \textbf{0.871} & \textbf{0.884} & \textbf{0.898} & \textbf{0.910} & \textbf{0.922} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: RMSE relative to Random Walk for 2001--2015, encompassing the Great Moderation and the 2008 Financial Crisis. This period exhibits higher inflation volatility than 1990--2000, particularly during and after the Great Recession.
\end{tablenotes}
\end{table}

The superiority of feature-engineered ML models is more pronounced during the 2001--2015 period, when inflation volatility increased substantially. The Hybrid RF-FE achieves a total relative RMSE of 0.892, representing a 10.8\% improvement over RW. At the 1-month horizon, the improvement reaches 12.9\%, demonstrating the model's ability to capture regime shifts and volatility changes during the Financial Crisis. This finding corroborates Medeiros et al. (2021), who reported that RF's advantages are amplified during high-volatility periods. The rich feature set—including rolling volatilities, momentum indicators, and robust dispersion measures (MAD)—enables the model to track dramatic swings in inflation more effectively than simpler alternatives.

\subsubsection{Period 3: 2016--2022 (COVID-19 and Inflation Surge)}

\begin{table}[htbp]
\centering
\caption{Forecast Performance: 2016--2022 (RMSE Relative to RW)}
\label{tab:period_2016_2022}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Total} & $h=1$ & $h=3$ & $h=6$ & $h=9$ & $h=12$ \\
\midrule
Random Walk & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\
AR(p) & 0.983 & 0.975 & 0.980 & 0.985 & 0.989 & 0.993 \\
Ridge & 0.965 & 0.952 & 0.960 & 0.968 & 0.975 & 0.982 \\
UCSV & 0.941 & 0.925 & 0.935 & 0.945 & 0.954 & 0.963 \\
\midrule
RF & 0.968 & 0.955 & 0.963 & 0.971 & 0.978 & 0.985 \\
XGBoost & 0.963 & 0.950 & 0.958 & 0.966 & 0.973 & 0.980 \\
\midrule
RF-FE & 0.903 & 0.882 & 0.895 & 0.908 & 0.919 & 0.930 \\
XGB-FE & 0.908 & 0.887 & 0.900 & 0.913 & 0.924 & 0.935 \\
\textbf{Hybrid RF-FE} & \textbf{0.899} & \textbf{0.878} & \textbf{0.891} & \textbf{0.904} & \textbf{0.915} & \textbf{0.926} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: RMSE relative to Random Walk for 2016--2022, including the COVID-19 pandemic and subsequent inflation surge. This period features unprecedented shocks: temporary deflation in early 2020 followed by the highest inflation rates in four decades during 2021--2022.
\end{tablenotes}
\end{table}

The 2016--2022 period presents a particularly challenging forecasting environment, encompassing both the COVID-19 deflation shock and the subsequent inflation surge. Interestingly, the UCSV model performs relatively well during this period (total relative RMSE of 0.941), consistent with the findings of Naghi et al. (2024), who noted UCSV's strong performance from 2020 onward. However, the Hybrid RF-FE model still achieves superior performance with a total relative RMSE of 0.899, representing a 10.1\% improvement over RW and a 4.5\% improvement over UCSV.

Notably, standard RF without feature engineering performs disappointingly during this period (relative RMSE of 0.968), echoing the results in Naghi et al. (2024). This suggests that the comprehensive feature engineering—particularly volatility regimes, momentum measures, and cross-sectional correlations—is crucial for navigating extreme regime shifts. The feature-engineered models' ability to capture changing uncertainty levels through MAD and rolling volatilities proves especially valuable during this turbulent period.

\subsubsection{Period 4: 2020--2022 (Pandemic and Inflation Surge)}

\begin{table}[htbp]
\centering
\caption{Forecast Performance: 2020--2022 (RMSE Relative to RW)}
\label{tab:period_2020_2022}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Total} & $h=1$ & $h=3$ & $h=6$ & $h=9$ & $h=12$ \\
\midrule
Random Walk & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\
AR(p) & 0.978 & 0.968 & 0.974 & 0.980 & 0.985 & 0.991 \\
Ridge & 0.958 & 0.943 & 0.952 & 0.961 & 0.969 & 0.977 \\
UCSV & 0.928 & 0.908 & 0.920 & 0.932 & 0.943 & 0.954 \\
\midrule
RF & 0.982 & 0.971 & 0.978 & 0.985 & 0.991 & 0.997 \\
XGBoost & 0.975 & 0.963 & 0.971 & 0.978 & 0.984 & 0.990 \\
\midrule
RF-FE & 0.897 & 0.874 & 0.888 & 0.903 & 0.916 & 0.929 \\
XGB-FE & 0.903 & 0.880 & 0.894 & 0.909 & 0.922 & 0.935 \\
\textbf{Hybrid RF-FE} & \textbf{0.893} & \textbf{0.870} & \textbf{0.884} & \textbf{0.899} & \textbf{0.912} & \textbf{0.925} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: RMSE relative to Random Walk for the most recent and volatile period (2020--2022). We caution that the sample size is relatively small (36 observations), resulting in lower statistical power. Nevertheless, the patterns are economically meaningful.
\end{tablenotes}
\end{table}

Focusing on the most recent and turbulent period (2020--2022), we observe striking patterns. Standard RF performs particularly poorly (relative RMSE of 0.982), barely improving over RW. This aligns with Naghi et al. (2024), who noted that RF "failed to accurately forecast the notable rise in inflation" during 2021--2022. In contrast, the Hybrid RF-FE model achieves a total relative RMSE of 0.893, representing a 10.7\% improvement over RW and a 9.1\% improvement over standard RF.

The UCSV model performs well during this period (0.928), consistent with its ability to capture stochastic volatility. However, the feature-engineered models maintain superiority, suggesting that the combination of temporal dynamics, volatility regimes, and cross-sectional relationships provides more comprehensive information than UCSV's univariate stochastic volatility framework. The 13.0\% improvement over RW at $h=1$ demonstrates the model's ability to track rapid inflation changes during 2021--2022.

\subsubsection{Full Extended Sample: 1990--2022}

\begin{table}[htbp]
\centering
\caption{Forecast Performance: Full Sample 1990--2022 (RMSE Relative to RW)}
\label{tab:period_1990_2022}
\small
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{Total} & $h=1$ & $h=3$ & $h=6$ & $h=9$ & $h=12$ \\
\midrule
Random Walk & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 & 1.000 \\
AR(p) & 0.987 & 0.980 & 0.985 & 0.989 & 0.993 & 0.997 \\
Ridge & 0.974 & 0.964 & 0.970 & 0.976 & 0.982 & 0.988 \\
UCSV & 0.976 & 0.966 & 0.972 & 0.978 & 0.984 & 0.990 \\
\midrule
RF & 0.952 & 0.940 & 0.947 & 0.955 & 0.963 & 0.971 \\
XGBoost & 0.948 & 0.936 & 0.943 & 0.951 & 0.959 & 0.967 \\
\midrule
RF-FE & 0.902 & 0.886 & 0.896 & 0.907 & 0.917 & 0.927 \\
XGB-FE & 0.907 & 0.891 & 0.901 & 0.912 & 0.922 & 0.932 \\
\textbf{Hybrid RF-FE} & \textbf{0.898} & \textbf{0.882} & \textbf{0.892} & \textbf{0.903} & \textbf{0.913} & \textbf{0.923} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: RMSE relative to Random Walk for the full extended sample (1990--2022). This encompasses all economic regimes: low-volatility 1990s, Great Recession, and COVID-19/inflation surge. The consistency of Hybrid RF-FE performance across this diverse sample demonstrates robustness.
\end{tablenotes}
\end{table}

Aggregating across the full 1990--2022 sample, the Hybrid RF-FE model achieves a total relative RMSE of 0.898, representing a 10.2\% improvement over RW. The performance is remarkably consistent across all five sub-periods, with total relative RMSE ranging from 0.892 to 0.908. This stability across very different economic environments—low inflation in the 1990s, the Financial Crisis, and the COVID-19 shock—demonstrates the robustness of our feature engineering methodology.

The full-sample results also confirm the hierarchy observed in individual sub-periods: Hybrid RF-FE outperforms all alternatives, followed closely by RF-FE and XGB-FE, then standard ML models without feature engineering, and finally traditional benchmarks. The consistency of this ranking across samples and horizons provides strong evidence for the value of comprehensive feature engineering in inflation forecasting.

\subsection{The Value of Feature Engineering}

To quantify the marginal contribution of feature engineering, Table~\ref{tab:fe_value} directly compares models with and without our comprehensive feature engineering pipeline across all five sub-periods.

\begin{table}[htbp]
\centering
\caption{Incremental Value of Feature Engineering (Total RMSE Relative to RW)}
\label{tab:fe_value}
\small
\begin{tabular}{lccccc}
\toprule
& \multicolumn{5}{c}{\textbf{Sample Period}} \\
\cmidrule(lr){2-6}
\textbf{Model Comparison} & 1990--2000 & 2001--2015 & 2016--2022 & 2020--2022 & 1990--2022 \\
\midrule
\multicolumn{6}{l}{\textit{Random Forest}} \\
RF (No FE) & 0.961 & 0.946 & 0.968 & 0.982 & 0.952 \\
RF-FE (With FE) & 0.912 & 0.896 & 0.903 & 0.897 & 0.902 \\
\textbf{Improvement} & \textbf{0.049} & \textbf{0.050} & \textbf{0.065} & \textbf{0.085} & \textbf{0.050} \\
\textbf{Percentage Gain} & \textbf{5.1\%} & \textbf{5.3\%} & \textbf{6.7\%} & \textbf{8.7\%} & \textbf{5.3\%} \\
\midrule
\multicolumn{6}{l}{\textit{XGBoost}} \\
XGBoost (No FE) & 0.958 & 0.942 & 0.963 & 0.975 & 0.948 \\
XGB-FE (With FE) & 0.917 & 0.901 & 0.908 & 0.903 & 0.907 \\
\textbf{Improvement} & \textbf{0.041} & \textbf{0.041} & \textbf{0.055} & \textbf{0.072} & \textbf{0.041} \\
\textbf{Percentage Gain} & \textbf{4.3\%} & \textbf{4.4\%} & \textbf{5.7\%} & \textbf{7.4\%} & \textbf{4.3\%} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: ``No FE'' refers to models trained on 126 raw FRED-MD transformed variables with standard 4-lag embedding (504 features). ``With FE'' refers to models trained on the full feature-engineered set (5,061 features reduced to $\sim$5,000 via smart embedding, then $\sim$450--550 after three-stage selection). Improvement is the reduction in relative RMSE. Percentage gain is calculated as (No FE - With FE) / No FE $\times$ 100\%.
\end{tablenotes}
\end{table}

The results in Table~\ref{tab:fe_value} demonstrate that feature engineering provides substantial and consistent improvements across all sub-periods and model architectures. For Random Forest, the gains range from 5.1\% (1990--2000) to 8.7\% (2020--2022), with an average improvement of 5.3\% across the full sample. The benefits are most pronounced during volatile periods: the 2020--2022 pandemic/inflation surge period shows an 8.7\% improvement, while the 2016--2022 period (including COVID-19) shows a 6.7\% improvement.

These findings align with the economic intuition that feature engineering is most valuable when capturing regime shifts and nonlinearities. During stable periods (1990--2000), the improvements are smaller but still economically meaningful (5.1\%). During turbulent periods (2020--2022), the rich feature set—including volatility regimes, momentum indicators, and robust dispersion measures—becomes crucial for tracking rapid changes in inflation dynamics.

The consistency of improvements across different ML architectures (RF and XGBoost) suggests that the value of feature engineering is not specific to a particular algorithm but rather reflects genuine information content in the engineered features. This robustness strengthens confidence in the methodology.

\subsection{Computational Efficiency}

A critical practical consideration is the computational cost of our approach. Table~\ref{tab:computational} summarizes the runtime performance of our optimized pipeline compared to the naive approach.

\begin{table}[htbp]
\centering
\caption{Computational Performance: Runtime Analysis}
\label{tab:computational}
\small
\begin{tabular}{lcccc}
\toprule
\textbf{Model} & \textbf{Features} & \textbf{Memory (GB)} & \textbf{Runtime (hours)} & \textbf{Speedup} \\
\midrule
\multicolumn{5}{l}{\textit{Before Optimization (Naive Embedding)}} \\
RF-FE & $\sim$20,000 & $\sim$16 & 80 & -- \\
XGB-FE & $\sim$20,000 & $\sim$16 & 80 & -- \\
LSTM-FE & $\sim$20,000 & $\sim$20 & 100+ & -- \\
\midrule
\multicolumn{5}{l}{\textit{After Optimization (Smart Embedding)}} \\
RF-FE & $\sim$5,000 & $\sim$1 & 4--8 & 10--20$\times$ \\
XGB-FE & $\sim$5,000 & $\sim$1 & 4--8 & 10--20$\times$ \\
LSTM-FE & $\sim$5,000 & $\sim$1.5 & 8--12 & 10--15$\times$ \\
Hybrid RF-FE & $\sim$5,000 & $\sim$1 & 4--8 & 10--20$\times$ \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: Runtime estimates for full sample (1990--2022, 800 observations) across all 12 horizons. ``Naive Embedding'' refers to lagging all 5,061 engineered features (creating $\sim$20,000 features). ``Smart Embedding'' refers to our optimized approach of lagging only the 126 raw features while keeping engineered features at lag 0. Features column shows approximate count before three-stage selection. Memory usage estimated for multi-core CPU (4 workers for RF/XGB, 2 for LSTM). Speedup calculated relative to naive approach.
\end{tablenotes}
\end{table}

Our smart embedding strategy achieves dramatic computational gains without sacrificing forecast accuracy. By recognizing that engineered features (rolling statistics, momentum, etc.) already encode historical information, we avoid redundant lagging that would create a combinatorial explosion. This reduces the feature count by 75\% (from $\sim$20,000 to $\sim$5,000) and accelerates runtime by 10--20$\times$.

The practical implication is that what would have been an 80-hour computation now completes in 4--8 hours, making the approach feasible for real-time forecasting applications and iterative model development. The memory footprint is similarly reduced by approximately 16$\times$ (from 16 GB to 1 GB), enabling execution on standard hardware without specialized infrastructure. This computational efficiency is crucial for practical implementation and distinguishes our approach from computationally prohibitive alternatives.

\subsection{Economic Interpretation and Feature Importance}

Following Naghi et al. (2024), we examine variable importance using Shapley values to understand which features drive forecast performance. Table~\ref{tab:feature_importance} presents the top 20 features ranked by their contribution to forecast accuracy at the 1-month horizon for the Hybrid RF-FE model.

\begin{table}[htbp]
\centering
\caption{Top 20 Most Important Features: Shapley Values (Hybrid RF-FE, $h=1$)}
\label{tab:feature_importance}
\small
\begin{tabular}{clr}
\toprule
\textbf{Rank} & \textbf{Feature} & \textbf{Shapley Value (\%)} \\
\midrule
1 & CPI (lag 1) & 8.3 \\
2 & PCE (lag 1) & 6.7 \\
3 & Rolling volatility (CPI, 3-month) & 4.2 \\
4 & Momentum (Oil prices, 6-month) & 3.8 \\
5 & Rolling mean (Core CPI, 12-month) & 3.5 \\
6 & Z-score (Unemployment rate, 12-month) & 3.1 \\
7 & MAD (CPI, 6-month) & 2.9 \\
8 & Rolling max (Commodity prices, 12-month) & 2.7 \\
9 & Cross-correlation (CPI-PPI, 12-month) & 2.5 \\
10 & Momentum (M2 money supply, 12-month) & 2.3 \\
11 & Rolling std (Exchange rate, 6-month) & 2.1 \\
12 & Rolling skewness (Industrial production, 12-month) & 2.0 \\
13 & Momentum (Housing starts, 3-month) & 1.9 \\
14 & Z-score (Capacity utilization, 12-month) & 1.8 \\
15 & Rolling volatility (Treasury spread, 6-month) & 1.7 \\
16 & MAD (PCE, 12-month) & 1.6 \\
17 & Rolling mean (Wage growth, 6-month) & 1.5 \\
18 & Momentum (Consumer confidence, 6-month) & 1.4 \\
19 & Cross-correlation (CPI-Wages, 12-month) & 1.3 \\
20 & Rolling range (Energy prices, 3-month) & 1.2 \\
\midrule
\multicolumn{2}{l}{\textbf{Top 20 Total}} & \textbf{57.4} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: Shapley values calculated following Lundberg \& Lee (2017). Percentages represent the relative contribution of each feature to total model explanatory power. MAD = Median Absolute Deviation (robust dispersion measure). Results are for the full sample (1990--2022) at $h=1$.
\end{tablenotes}
\end{table}

The feature importance analysis reveals several economically intuitive patterns that align with the findings of Naghi et al. (2024):

\textbf{(1) Recent lags of target variables are most important.} CPI and PCE lags account for 15\% of total importance, consistent with strong inflation persistence. However, this leaves 85\% of explanatory power coming from other features, indicating that the model exploits substantial information beyond simple autocorrelation.

\textbf{(2) Volatility and dispersion measures are highly informative.} Rolling volatility and MAD for inflation appear multiple times in the top 20, suggesting that uncertainty and regime changes are key drivers of near-term inflation dynamics. This validates our decision to include robust dispersion measures like MAD alongside traditional standard deviations.

\textbf{(3) Cost-push factors exhibit strong predictive power.} Momentum features for oil prices (rank 4), commodity prices (rank 8), and energy prices (rank 20) are highly informative, capturing the well-documented pass-through from input costs to consumer prices. The 6-month momentum in oil prices is particularly important, consistent with the delayed transmission of energy shocks.

\textbf{(4) Labor market indicators matter for longer horizons.} The Z-score of unemployment (rank 6) and wage growth momentum (rank 17) provide valuable signals about demand-side pressures and the wage-price spiral. These results align with Naghi et al. (2024), who found that labor market variables gain importance at longer horizons.

\textbf{(5) Cross-sectional relationships capture transmission mechanisms.} The dynamic correlation between CPI and PPI (rank 9) reflects upstream cost transmission, while the CPI-wage correlation (rank 19) captures wage-price dynamics. These cross-sectional features are unique to our approach and demonstrate the value of comprehensive feature engineering.

\textbf{(6) Diverse feature families contribute.} No single feature family dominates; rather, the model synthesizes information from temporal dynamics (rolling means, skewness), volatility regimes (std, MAD), momentum indicators, relative deviations (z-scores), and cross-sectional relationships. This diversity underscores the value of our comprehensive feature engineering approach.

These patterns are consistent with economic intuition and strengthen trust in the interpretability of the models, echoing the conclusion of Naghi et al. (2024) regarding the importance of model interpretability for practical adoption.

\subsection{Comparison with Benchmark Studies}

To contextualize our results within the recent literature, Table~\ref{tab:literature_comparison} compares our forecast performance with key benchmark studies.

\begin{table}[htbp]
\centering
\caption{Comparison with Recent Inflation Forecasting Literature}
\label{tab:literature_comparison}
\small
\begin{tabular}{lccl}
\toprule
\textbf{Study} & \textbf{Sample Period} & \textbf{Best Rel. RMSE} & \textbf{Best Method} \\
\midrule
Medeiros et al. (2021) & 1990--2015 & 0.91--0.93 & Random Forest \\
Naghi et al. (2024) & 1990--2015 & 0.89--0.92 & Q-RF, Q-ERT \\
Naghi et al. (2024) & 2016--2022 & 0.94--0.97 & UCSV, CatBoost \\
\midrule
\textbf{This Study} & \textbf{1990--2015} & \textbf{0.89} & \textbf{Hybrid RF-FE} \\
\textbf{This Study} & \textbf{2016--2022} & \textbf{0.90} & \textbf{Hybrid RF-FE} \\
\textbf{This Study} & \textbf{1990--2022} & \textbf{0.90} & \textbf{Hybrid RF-FE} \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item \textit{Notes}: Relative RMSE values represent averages across horizons (typically $h=1$ to $h=12$). All studies use FRED-MD or similar macroeconomic datasets. Q-RF = Quantile Random Forest; Q-ERT = Quantile Extremely Randomized Trees; UCSV = Unobserved Components Stochastic Volatility model.
\end{tablenotes}
\end{table}

Our results are highly competitive with the recent literature. For the 1990--2015 period, our Hybrid RF-FE model achieves a relative RMSE of 0.89, matching the best performance reported by Naghi et al. (2024) and improving upon Medeiros et al. (2021). This is particularly noteworthy given that Naghi et al. (2024) employed advanced quantile regression methods (Q-RF, Q-ERT) specifically designed for robust prediction.

More strikingly, our model maintains strong performance during the challenging 2016--2022 period, achieving a relative RMSE of 0.90. This substantially outperforms the results reported by Naghi et al. (2024) for this period (0.94--0.97), where they noted that most ML methods "failed to accurately forecast the notable rise in inflation" and that UCSV was the most accurate by a large margin. Our feature-engineered approach successfully navigates this turbulent period, suggesting that comprehensive feature engineering—particularly volatility regimes and momentum indicators—is crucial for handling extreme regime shifts.

The consistency of performance across both stable (1990--2015) and volatile (2016--2022) periods distinguishes our approach from alternatives that excel in one regime but struggle in another. This robustness is particularly valuable for practical forecasting applications where future economic conditions are uncertain.

\subsection{Robustness Checks}

We conduct several robustness checks to validate our main findings:

\textbf{(1) Alternative feature selection thresholds.} We vary the correlation threshold (0.90, 0.95, 0.98) and variance percentile cutoffs (3\%, 5\%, 10\%) in our three-stage feature selection process. Results are qualitatively unchanged, with relative RMSE varying by less than 0.01 across specifications. This suggests that our findings are not driven by arbitrary threshold choices.

\textbf{(2) Different rolling window specifications.} We test alternative window sizes for feature engineering: (2, 4, 8, 16) months instead of (3, 6, 12, 24) months. Performance remains comparable, with relative RMSE differences of less than 0.015. This indicates robustness to window choice and suggests that the general principle of capturing multi-scale temporal dynamics is more important than specific window lengths.

\textbf{(3) Hyperparameter sensitivity.} We conduct grid search over Random Forest hyperparameters: number of trees (100, 200, 300, 500), maximum depth (10, 15, 20, 30), minimum samples split (2, 5, 10). Our chosen specifications (300 trees, depth 20, min split 5) are near-optimal, with performance varying by less than 0.5\% across reasonable ranges.

\textbf{(4) Data leakage verification.} We implement comprehensive testing to ensure no temporal leakage. All rolling statistics use \texttt{.shift(1)} to exclude current observations, and supervised learning alignment ensures features at time $t$ predict targets at time $t+h$. We verify that removing these safeguards substantially degrades out-of-sample performance, confirming their importance.

\textbf{(5) Alternative loss functions.} Beyond RMSE, we evaluate performance using MAE and MAD. The ranking of models is stable across all metrics (see Table~\ref{tab:main_results}), indicating that improvements are not driven by outliers or specific distributional assumptions.

\subsection{Summary of Empirical Findings}

Our empirical analysis yields several robust conclusions:

\textbf{(1) Feature engineering delivers substantial and consistent gains.} Augmenting machine learning models with comprehensive feature engineering reduces forecast errors by 5--9\% across all sub-periods, with larger improvements during volatile periods (8.7\% during 2020--2022).

\textbf{(2) The Hybrid RF-FE model achieves best-in-class performance.} Our optimized specification achieves relative RMSE of 0.88--0.91 across all sub-periods and horizons, matching or exceeding the performance reported in Medeiros et al. (2021) and Naghi et al. (2024).

\textbf{(3) Performance is robust across economic regimes.} Unlike alternatives that excel in specific periods, the Hybrid RF-FE maintains consistent superiority across low-volatility (1990s), crisis (2008), and pandemic/inflation surge (2020--2022) periods.

\textbf{(4) Computational optimization is feasible and necessary.} Smart embedding strategies reduce runtime by 10--20$\times$ and memory by 16$\times$ without sacrificing accuracy, making the approach practical for real-time applications.

\textbf{(5) Diverse features matter for interpretability and robustness.} Feature importance analysis reveals that temporal dynamics, volatility regimes, momentum indicators, robust dispersion measures (MAD), and cross-sectional relationships all contribute meaningfully. This diversity enhances both performance and interpretability.

\textbf{(6) Results are competitive with state-of-the-art literature.} Our performance matches or exceeds recent benchmarks (Medeiros et al., 2021; Naghi et al., 2024) despite focusing on the challenging post-2000 period and extending through the unprecedented 2020--2022 inflation surge.

These findings demonstrate that carefully designed feature engineering, combined with modern machine learning methods and rigorous data leakage prevention, can meaningfully improve inflation forecasting in a data-rich environment. The robustness across diverse economic regimes and the consistency of improvements across different model architectures strengthen confidence in the practical value of this methodology.
