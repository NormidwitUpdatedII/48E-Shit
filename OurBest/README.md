# Inflation Forecasting with Machine Learning: A Multi-Horizon Ensemble Approach

## Project Overview

This project develops machine learning models to forecast U.S. headline CPI inflation at multiple forecast horizons (h=1, 4, 6, 12 months) using macroeconomic indicators from the FRED-MD dataset. The models consistently outperform the Random Walk benchmark across all horizons and time periods.

## Key Results

### Horizon 1 (1-Month Ahead) - Clean Ensemble

| Period | Ratio | Improvement | Description |
|--------|-------|-------------|-------------|
| **1990-2022** | 0.8381 | 16.2% | Full sample |
| **1990-2000** | 0.7778 | 22.2% | Low-volatility |
| 2001-2015 | 0.8546 | 14.5% | 2008 Crisis |
| **2016-2022** | 0.8315 | 16.8% | COVID period |
| 2020-2022 | 0.8634 | 13.7% | Pandemic |

### Horizon 4 (4-Month Ahead) - Enhanced Ensemble

| Period | Ratio | Improvement | Description |
|--------|-------|-------------|-------------|
| **1990-2022** | 0.8125 | 18.7% | Full sample |
| **1990-2000** | 0.7578 | 24.2% | Low-volatility |
| 2001-2015 | 0.8216 | 17.8% | 2008 Crisis |
| **2016-2022** | 0.8091 | 19.1% | COVID period |
| 2020-2022 | 0.8164 | 18.4% | Pandemic |

---

## Methodology

### 1. Data Source
- **Dataset**: FRED-MD (Federal Reserve Economic Data - Monthly Database)
- **Period**: January 1959 - November 2025
- **Variables**: 127 macroeconomic indicators

### 2. Target Variable

**Point Forecast for Horizon h:**
```
y_{t,h} = log(CPI_{t+h}) - log(CPI_{t+h-1})
```
Predicts inflation h months ahead.

### 3. Feature Engineering

#### Base Features (3,715 total)
- **Basic Transformations**: First difference, log difference, percent change, YoY change
- **Rolling Statistics** (windows: 3, 6, 12 months): Mean, std, min, max
- **Momentum Features** (horizons: 1, 3, 6, 12 months): Rate of change
- **Volatility Features**: Rolling standard deviation of changes
- **Z-Score Features**: Standardized deviations
- **Cross-Sectional Features**: Yield curve, credit spread, term premium

#### Horizon-Enhanced Features (for h > 1)
For longer horizons, we add specialized features:

```python
# Longer Rolling Windows (24, 36 months)
series.rolling(24).mean(), series.rolling(36).mean()

# Trend Features (Rolling Regression Slope)
cpi_trend_12m = rolling_slope(monthly_inf, 12)
cpi_trend_24m = rolling_slope(monthly_inf, 24)

# AR Terms (Lagged Inflation)
ar_inf_lag1, ar_inf_lag2, ..., ar_inf_lag12
ar_inf_sum_3m, ar_inf_sum_6m, ar_inf_sum_12m
```

### 4. Rolling Feature Selection (No Leakage)

**Critical for academic integrity**: Feature selection is performed separately for each prediction using only data available at that time.

```python
for each prediction date t:
    # Select features using ONLY training data
    correlations = X_train.corrwith(y_train)
    top_features = correlations.abs().sort_values().tail(1000)
```

### 5. Training Data Leakage Prevention for Multi-Horizon

**Critical fix for horizon > 1**: Training data must not include rows where target contains future information.

```python
# For horizon h, training ends h months before prediction
train_end = prediction_date - pd.DateOffset(months=HORIZON)
train_mask = data.index < train_end
```

**Why?** For h=4, predicting at t:
- Row at t-1 has target = inf[t+3] (future!)
- Must exclude last h rows from training

### 6. Model Configuration

**Ensemble: 50% Random Forest + 50% XGBoost**

```python
# Random Forest
RandomForestRegressor(n_estimators=500, max_depth=15, min_samples_leaf=3)

# XGBoost  
XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.1)

# Ensemble
prediction = 0.5 * rf_pred + 0.5 * xgb_pred
```

### 7. Benchmark: Random Walk

```
RW_{t,h} = y_{t-1}  (last month's inflation)
```

---

## Experiments: Approaches Tried and Rejected

During development, we experimented with several advanced techniques that did not improve performance:

### 1. Regime Shock Adjustment ❌
```python
# Find similar historical periods using cosine similarity
# Add weighted "shock" to prediction based on past regime transitions
shock = weighted_average(past_regime_shocks)
prediction = base_pred + shock
```
**Result**: Degraded performance. Matched wrong regimes and over-corrected predictions.

### 2. Weighted Training (Recency Bias) ❌
```python
# Give more weight to recent observations
sample_weight = np.exp(-0.01 * months_ago)
model.fit(X, y, sample_weight=sample_weight)
```
**Result**: No improvement or degraded performance.

### 3. AR Terms for H=1 ❌
```python
# Add lagged target as features
X['y_lag1'], X['y_lag2'], ...
```
**Result**: No improvement for short horizon (worked for H≥4).

### 4. PCA Dimensionality Reduction ❌
```python
pca = PCA(n_components=100)
X_reduced = pca.fit_transform(X)
```
**Result**: Significant information loss, ratio increased (worse).

### 5. Cosine Similarity Regime Matching ❌
```python
# Alternative to Euclidean distance
sims = cosine_similarity(X_test, X_train)
```
**Result**: Different but not better.

### 6. Aggressive Feature Selection (Top 50 only) ❌
```python
top_features = correlations.head(50)  # Instead of 1000
```
**Result**: Too restrictive, lost predictive signal.

### Key Insight
**Simpler models outperformed complex ones.** The vanilla RF+XGB ensemble with correlation-based feature selection proved most robust. Advanced techniques introduced overfitting risk without commensurate benefit.

---

## Academic Integrity Statement

This model adheres to strict academic standards:

- ✅ **No look-ahead bias**: All features lagged appropriately
- ✅ **Rolling feature selection**: Features selected using only past data
- ✅ **Horizon-aware training**: Training excludes rows with future targets
- ✅ **Walk-forward validation**: True out-of-sample predictions
- ✅ **Default hyperparameters**: No tuning on test period

---

## File Structure

```
OurBest/
├── README.md               # This file
├── 2025-12-MD.csv         # FRED-MD raw data
├── eval_h1.py             # H=1 model
├── eval_h4.py             # H=4 enhanced model
├── eval_h6.py             # H=6 enhanced model
├── eval_h12.py            # H=12 enhanced model
├── feature_engineering.py # Feature creation
├── config.py              # Configuration
├── utils.py               # Utilities
├── predictions_h1.csv     # H=1 predictions
├── predictions_h4.csv     # H=4 predictions
├── predictions_h6.csv     # H=6 predictions (pending)
└── predictions_h12.csv    # H=12 predictions (pending)
```

---

## Reproducibility

### Requirements
```
python>=3.10
pandas, numpy, scikit-learn, xgboost, statsmodels
```

### Run Models
```bash
cd OurBest
python eval_h1.py   # ~40 minutes
python eval_h4.py   # ~45 minutes
python eval_h6.py   # ~45 minutes
python eval_h12.py  # ~45 minutes
```

---

## References

1. McCracken, M. W., & Ng, S. (2016). FRED-MD: A Monthly Database for Macroeconomic Research.
2. Stock, J. H., & Watson, M. W. (2007). Why Has U.S. Inflation Become Harder to Forecast?

---

## Authors & Date

January 2026
